{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "chicken-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Definimos entidades a buscar a partir de scraping de ENISA\n",
    "entity_list = pd.read_csv('df_enisa.csv', sep=';')\n",
    "entity_list = entity_list[\"Marca\"].to_list()\n",
    "\n",
    "# Buscamos la fecha de hace 3 meses\n",
    "today = dt.date.today()\n",
    "fecha = today - dt.timedelta(days=90)\n",
    "\n",
    "# Creamos la lista para recopilar tweets\n",
    "tweets_list = []\n",
    "tweets_enisa_list = []\n",
    "\n",
    "for entity in entity_list:\n",
    "    search = entity + \" since:\" + str(fecha)\n",
    "    search_enisa = entity + \" #clienteEnisa since:\" + str(fecha)\n",
    "\n",
    "    # Usamos TwitterSearchScraper para scrapear datos y guardar tweets en lista - Marca\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search).get_items()):\n",
    "        if i>500:\n",
    "            break\n",
    "        tweets_list.append([entity, tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "\n",
    "    # Usamos TwitterSearchScraper para scrapear datos y guardar tweets en lista - menciones enisa\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search_enisa).get_items()):\n",
    "        if i>500:\n",
    "            break\n",
    "        tweets_enisa_list.append([entity, tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "\n",
    "# Creamos dataframes con toda la inforamción - por si potencialmente se quieren trabajar los datos\n",
    "df_tweets = pd.DataFrame(tweets_list, columns=['Marca', 'Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "df_tweets_enisa = pd.DataFrame(tweets_enisa_list, columns=['Marca', 'Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "\n",
    "# Creamos dataframes con indicador de tweets en últimos 90d\n",
    "df_90d = df_tweets.Marca.value_counts().to_frame(name='90d_enisa')\n",
    "df_90d['Marca'] = df_90d.index\n",
    "df_90d.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_90d_enisa = df_tweets_enisa.Marca.value_counts().to_frame(name='90d_enisa')\n",
    "df_90d_enisa['Marca'] = df_90d_enisa.index\n",
    "df_90d_enisa.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Generamos los ficheros de salida CSV\n",
    "df_90d.to_csv('df_twitter_90d.csv', sep=\";\", na_rep= \"\",)\n",
    "df_90d_enisa.to_csv('df_twitter_90d_enisa.csv', sep=\";\", na_rep= \"\",)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
